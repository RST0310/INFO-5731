{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343202d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in c:\\users\\saite\\anaconda3\\lib\\site-packages (2.7.14)\n",
      "Requirement already satisfied: scipy in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (1.9.1)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (3.7.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (1.4.4)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: pip in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (22.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (2.28.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (3.5.2)\n",
      "Requirement already satisfied: torch<2.3,>=1.10 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (2.2.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (9.2.0)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (1.5.29)\n",
      "Requirement already satisfied: packaging in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: torchvision>=0.11 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (0.17.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (63.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.3.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.21.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.4.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.6.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from packaging->fastai) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from requests->fastai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from requests->fastai) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from requests->fastai) (1.26.11)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (4.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saite\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saite\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\saite\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saite\\anaconda3\\lib\\site-packages (from torch<2.3,>=1.10->fastai) (2022.7.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from pandas->fastai) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\saite\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saite\\anaconda3\\lib\\site-packages (from sympy->torch<2.3,>=1.10->fastai) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2509d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e071b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"IPL_Match_Highlights_Commentary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40ad7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text\n",
    "\n",
    "data['Commentary'] = data['Commentary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8df955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Tokenization\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data['tokenized_commentary'] = data['Commentary'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Remove stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['cleaned_commentary'] = data['tokenized_commentary'].apply(lambda x: [word for word in x if (word not in stop_words) and (word not in string.punctuation)])\n",
    "\n",
    "# Feature Engineering\n",
    "data['processed_text'] = data['cleaned_commentary'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee86756e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_id</th>\n",
       "      <th>Team</th>\n",
       "      <th>Over_num</th>\n",
       "      <th>Commentary</th>\n",
       "      <th>batsman</th>\n",
       "      <th>score</th>\n",
       "      <th>tokenized_commentary</th>\n",
       "      <th>cleaned_commentary</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4281444</td>\n",
       "      <td>RCB 1st Inns</td>\n",
       "      <td>0.5</td>\n",
       "      <td>nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence</td>\n",
       "      <td>Nehra to Mandeep</td>\n",
       "      <td>FOUR</td>\n",
       "      <td>[nehra, to, mandeep, four, first, boundary, for, mandeep, and, rcb, full, and, on, the, pads, needed, to, be, put, away, and, mandeep, did, just, that, picked, it, up, and, dispatched, it, over, midwicket, couple, of, bounces, and, into, the, fence]</td>\n",
       "      <td>[nehra, mandeep, four, first, boundary, mandeep, rcb, full, pads, needed, put, away, mandeep, picked, dispatched, midwicket, couple, bounces, fence]</td>\n",
       "      <td>nehra mandeep four first boundary mandeep rcb full pads needed put away mandeep picked dispatched midwicket couple bounces fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4281444</td>\n",
       "      <td>RCB 1st Inns</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly</td>\n",
       "      <td>Nehra to Mandeep</td>\n",
       "      <td>FOUR</td>\n",
       "      <td>[nehra, to, mandeep, four, backtoback, boundaries, to, end, the, first, over, again, nehra, is, a, tad, short, in, his, length, mandeep, had, the, width, to, cut, and, he, didnt, try, to, hit, it, hard, just, placed, it, behind, point, and, bhuvi, at, third, man, gave, up, the, chase, pretty, quickly]</td>\n",
       "      <td>[nehra, mandeep, four, backtoback, boundaries, end, first, nehra, tad, short, length, mandeep, width, cut, didnt, try, hit, hard, placed, behind, point, bhuvi, third, man, gave, chase, pretty, quickly]</td>\n",
       "      <td>nehra mandeep four backtoback boundaries end first nehra tad short length mandeep width cut didnt try hit hard placed behind point bhuvi third man gave chase pretty quickly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4281444</td>\n",
       "      <td>RCB 1st Inns</td>\n",
       "      <td>10.0</td>\n",
       "      <td>henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder</td>\n",
       "      <td>Henriques to Kedar Jadhav</td>\n",
       "      <td>FOUR</td>\n",
       "      <td>[henriques, to, kedar, jadhav, four, hit, straight, back, at, henriques, and, he, was, late, to, get, his, hand, up, once, more, the, offcutter, which, almost, fooled, jadhav, who, shimmied, down, and, checked, his, drive, middled, it, alright, to, beat, the, midoff, fielder]</td>\n",
       "      <td>[henriques, kedar, jadhav, four, hit, straight, back, henriques, late, get, hand, offcutter, almost, fooled, jadhav, shimmied, checked, drive, middled, alright, beat, midoff, fielder]</td>\n",
       "      <td>henriques kedar jadhav four hit straight back henriques late get hand offcutter almost fooled jadhav shimmied checked drive middled alright beat midoff fielder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_id          Team  Over_num  \\\n",
       "0   4281444  RCB 1st Inns       0.5   \n",
       "1   4281444  RCB 1st Inns       1.0   \n",
       "2   4281444  RCB 1st Inns      10.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                    Commentary  \\\n",
       "0                                             nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence   \n",
       "1  nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly   \n",
       "2                    henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder   \n",
       "\n",
       "                     batsman score  \\\n",
       "0           Nehra to Mandeep  FOUR   \n",
       "1           Nehra to Mandeep  FOUR   \n",
       "2  Henriques to Kedar Jadhav  FOUR   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                             tokenized_commentary  \\\n",
       "0                                                       [nehra, to, mandeep, four, first, boundary, for, mandeep, and, rcb, full, and, on, the, pads, needed, to, be, put, away, and, mandeep, did, just, that, picked, it, up, and, dispatched, it, over, midwicket, couple, of, bounces, and, into, the, fence]   \n",
       "1  [nehra, to, mandeep, four, backtoback, boundaries, to, end, the, first, over, again, nehra, is, a, tad, short, in, his, length, mandeep, had, the, width, to, cut, and, he, didnt, try, to, hit, it, hard, just, placed, it, behind, point, and, bhuvi, at, third, man, gave, up, the, chase, pretty, quickly]   \n",
       "2                            [henriques, to, kedar, jadhav, four, hit, straight, back, at, henriques, and, he, was, late, to, get, his, hand, up, once, more, the, offcutter, which, almost, fooled, jadhav, who, shimmied, down, and, checked, his, drive, middled, it, alright, to, beat, the, midoff, fielder]   \n",
       "\n",
       "                                                                                                                                                                                          cleaned_commentary  \\\n",
       "0                                                       [nehra, mandeep, four, first, boundary, mandeep, rcb, full, pads, needed, put, away, mandeep, picked, dispatched, midwicket, couple, bounces, fence]   \n",
       "1  [nehra, mandeep, four, backtoback, boundaries, end, first, nehra, tad, short, length, mandeep, width, cut, didnt, try, hit, hard, placed, behind, point, bhuvi, third, man, gave, chase, pretty, quickly]   \n",
       "2                    [henriques, kedar, jadhav, four, hit, straight, back, henriques, late, get, hand, offcutter, almost, fooled, jadhav, shimmied, checked, drive, middled, alright, beat, midoff, fielder]   \n",
       "\n",
       "                                                                                                                                                                 processed_text  \n",
       "0                                              nehra mandeep four first boundary mandeep rcb full pads needed put away mandeep picked dispatched midwicket couple bounces fence  \n",
       "1  nehra mandeep four backtoback boundaries end first nehra tad short length mandeep width cut didnt try hit hard placed behind point bhuvi third man gave chase pretty quickly  \n",
       "2               henriques kedar jadhav four hit straight back henriques late get hand offcutter almost fooled jadhav shimmied checked drive middled alright beat midoff fielder  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62cc311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11574, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7299067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence\n",
      "\n",
      "nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly\n",
      "\n",
      "henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder\n",
      "\n",
      "nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra hes missing the yorker by quite a bit\n",
      "\n",
      "nehra to kedar jadhav four four more jadhav starting to really find his timing now and hes looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure\n",
      "\n",
      "Total number of commentaries: 11574\n"
     ]
    }
   ],
   "source": [
    "total_commentaries = 11574\n",
    "for i in range(5):\n",
    "    commentary = data.Commentary[i]               # This is the text of row 'i'.\n",
    "    print(commentary)\n",
    "    print()\n",
    "\n",
    "print(\"Total number of commentaries:\", total_commentaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb52453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(\"./full_commentaries\", exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('IPL_Match_Highlights_Commentary.csv')\n",
    "\n",
    "# Iterate through the dataset and write commentary to text files\n",
    "for i in range(data.shape[0]):\n",
    "    commentary = data.Commentary[i]  # Extract commentary text\n",
    "    # Write commentary to a text file\n",
    "    with open(f\"./full_commentaries/{i}.txt\", \"w\") as f:\n",
    "        f.write(commentary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7060c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "# Set up the path to the directory containing text files\n",
    "inputpath = \"./full_commentaries\"\n",
    "\n",
    "# Function to get text files\n",
    "def get_text_files(path):\n",
    "    return get_files(path)\n",
    "\n",
    "# Collect all text files within the directory\n",
    "textfiles = get_text_files(inputpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a0590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DataBlock for processing text data\n",
    "commentary_loader = DataBlock(\n",
    "    blocks=TextBlock.from_folder(inputpath, is_lm=True),\n",
    "    get_items=get_text_files,\n",
    "    splitter=RandomSplitter(0.1),\n",
    ")\n",
    "\n",
    "# Create DataLoaders with n_workers set to 0\n",
    "commentary_dls = commentary_loader.dataloaders(inputpath, path=inputpath, bs=64, seq_len=70, n_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e0c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 01:40&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.349693</td>\n",
       "      <td>2.983691</td>\n",
       "      <td>0.420469</td>\n",
       "      <td>21:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.841616</td>\n",
       "      <td>2.745668</td>\n",
       "      <td>0.448002</td>\n",
       "      <td>14:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.608955</td>\n",
       "      <td>2.648421</td>\n",
       "      <td>0.460611</td>\n",
       "      <td>12:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.452137</td>\n",
       "      <td>2.602394</td>\n",
       "      <td>0.466729</td>\n",
       "      <td>12:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.343570</td>\n",
       "      <td>2.592847</td>\n",
       "      <td>0.468450</td>\n",
       "      <td>11:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.359983</td>\n",
       "      <td>2.624296</td>\n",
       "      <td>0.464703</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.410287</td>\n",
       "      <td>2.617390</td>\n",
       "      <td>0.465954</td>\n",
       "      <td>12:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.345498</td>\n",
       "      <td>2.593901</td>\n",
       "      <td>0.468471</td>\n",
       "      <td>13:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.262790</td>\n",
       "      <td>2.582800</td>\n",
       "      <td>0.471293</td>\n",
       "      <td>21:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.206158</td>\n",
       "      <td>2.581796</td>\n",
       "      <td>0.471401</td>\n",
       "      <td>20:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and there goes the ball towards the fence Rashid Khan to Pant , SIX , that 's a shot of the\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ball flies between Negi and Negi to Negi , FOUR , \" that 's \" class \" \"\n"
     ]
    }
   ],
   "source": [
    "# Initialize a language model learner\n",
    "learn = language_model_learner(commentary_dls, AWD_LSTM, drop_mult=0.3, metrics=accuracy).to_fp16()\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(5, 2e-2)\n",
    "learn.fit_one_cycle(5, 1e-2)\n",
    "\n",
    "# Generate predictions\n",
    "print(learn.predict(\"and there goes the ball towards\", 20, temperature=0.5))\n",
    "print(learn.predict(\"the ball flies\", 20, temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e6d3161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gayle hits his first maximum of the night on a good length . It travels to the long - off boundary'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Gayle hits\", 20, temperature = 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4739aec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The crowd xxunk as the crowd move Boult to Nitish Rana , FOUR , that 's too short ,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incredible shot ! Incredible shot ! Incredible shot ! Incredible Harshal Patel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bowler xxunk the crease with xxunk , Bairstow gets the biggest of the night . The dugout erupts in style . Kolkata have a southpaw who nonchalantly smokes it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stadium is packed with fans xxunk for their favorite team , it is on a good length , just outside off , on a full and just outside off ,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The match hangs in the balance as Bangalore lose their fifth ball . They have their highest score of the\n"
     ]
    }
   ],
   "source": [
    "print(learn.predict(\"The crowd erupted as\", 20, temperature=0.7))\n",
    "print(learn.predict(\"Incredible shot!\", 15, temperature=0.6))\n",
    "print(learn.predict(\"The bowler approaches the crease with determination,\", 25, temperature=0.7))\n",
    "print(learn.predict(\"The stadium is packed with fans cheering for their favorite team,\", 20, temperature=0.7))\n",
    "print(learn.predict(\"The match hangs in the balance as\", 15, temperature=0.6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efbb2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 13.22086690713197\n"
     ]
    }
   ],
   "source": [
    "# Evaluate perplexity on the validation set\n",
    "valid_loss = learn.validate()[0]\n",
    "\n",
    "# Calculate perplexity\n",
    "perplexity = np.exp(valid_loss)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "600bcf93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatched it over midwicket Dwayne Bravo to Gayle , out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he did xxunk try to hit it hard . But still got nothing more than a chance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who shimmied down and checked his drive . The ball clipped the inside edge , beat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing the yorker by quite a bit , Buttler misses by a couple of inches ,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling it over the fielder 's head for a maximum Tye to\n"
     ]
    }
   ],
   "source": [
    "print(learn.predict(\"dispatched it over midwicket\", 10, temperature=0.7))\n",
    "print(learn.predict(\"he didnt try to hit it hard\", 10, temperature=0.7))\n",
    "print(learn.predict(\"who shimmied down and checked his drive\", 10, temperature=0.7))\n",
    "print(learn.predict(\"missing the yorker by quite a bit\", 10, temperature=0.7))\n",
    "print(learn.predict(\"pulling it over the fielder\", 10, temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28eb3cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Commentary Tokens:\n",
      "['dispatched it over midwicket', 'he didnt try to hit it hard', 'who shimmied down and checked his drive', 'missing the yorker by quite a bit', 'pulling it over the fielder']\n",
      "\n",
      "Generated Commentary Tokens:\n",
      "[['dispatched', 'it', 'over', 'midwicket', 'Bhuvneshwar', 'to', 'Pant', ',', 'FOUR', ','], ['he', 'did', 'xxunk', 'try', 'to', 'hit', 'it', 'hard', '.', 'There', 'was', 'nothing', 'to', 'stop', 'it', ',', 'but'], ['who', 'shimmied', 'down', 'and', 'checked', 'his', 'drive', 'but', 'lost', 'his', 'balance', 'in', 'the', 'upper', 'half', 'of', 'the'], ['missing', 'the', 'yorker', 'by', 'quite', 'a', 'bit', 'to', 'the', 'left', 'of', 'Hetmyer', ',', 'who', 'swivels', ','], ['pulling', 'it', 'over', 'the', 'fielder', \"'s\", 'head', '.', 'There', 'was', 'never', 'a', 'clear', 'fielder']]\n"
     ]
    }
   ],
   "source": [
    "# Define the tokens\n",
    "tokens = [\n",
    "    \"dispatched it over midwicket\",\n",
    "    \"he didnt try to hit it hard\",\n",
    "    \"who shimmied down and checked his drive\",\n",
    "    \"missing the yorker by quite a bit\",\n",
    "    \"pulling it over the fielder\"\n",
    "]\n",
    "\n",
    "# Generate reference and generated commentary tokens\n",
    "reference_commentary_tokens = []\n",
    "generated_commentary_tokens = []\n",
    "\n",
    "for token in tokens:\n",
    "    # Generate prediction based on the token\n",
    "    prediction = learn.predict(token, 10, temperature=0.7)\n",
    "    \n",
    "    # Split prediction into tokens\n",
    "    generated_tokens = prediction.split()\n",
    "    \n",
    "    # Add original token to reference list\n",
    "    reference_commentary_tokens.append(token)\n",
    "    \n",
    "    # Add generated tokens to generated list\n",
    "    generated_commentary_tokens.append(generated_tokens)\n",
    "\n",
    "# Print reference and generated lists\n",
    "print(\"Reference Commentary Tokens:\")\n",
    "print(reference_commentary_tokens)\n",
    "print(\"\\nGenerated Commentary Tokens:\")\n",
    "print(generated_commentary_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2faca618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 2.1071373518345672e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Reference commentary tokens\n",
    "reference_commentary_tokens = [['dispatched it over midwicket'],\n",
    "                               ['he didnt try to hit it hard'],\n",
    "                               ['who shimmied down and checked his drive'],\n",
    "                               ['missing the yorker by quite a bit'],\n",
    "                               ['pulling it over the fielder']]\n",
    "\n",
    "# Generated commentary tokens\n",
    "generated_commentary_tokens = [['dispatched', 'it', 'over', 'midwicket', 'Bhuvneshwar', 'to', 'Pant', ',', 'FOUR', ','],\n",
    "                                ['he', 'did', 'xxunk', 'try', 'to', 'hit', 'it', 'hard', '.', 'There', 'was', 'nothing', 'to', 'stop', 'it', ',', 'but'],\n",
    "                                ['who', 'shimmied', 'down', 'and', 'checked', 'his', 'drive', 'but', 'lost', 'his', 'balance', 'in', 'the', 'upper', 'half', 'of', 'the'],\n",
    "                                ['missing', 'the', 'yorker', 'by', 'quite', 'a', 'bit', 'to', 'the', 'left', 'of', 'Hetmyer', ',', 'who', 'swivels', ','],\n",
    "                                ['pulling', 'it', 'over', 'the', 'fielder', \"'s\", 'head', '.', 'There', 'was', 'never', 'a', 'clear', 'fielder']]\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = corpus_bleu(reference_commentary_tokens, generated_commentary_tokens)\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e78174f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.360667</td>\n",
       "      <td>2.987018</td>\n",
       "      <td>0.422230</td>\n",
       "      <td>19.826473</td>\n",
       "      <td>11:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.848392</td>\n",
       "      <td>2.758508</td>\n",
       "      <td>0.442510</td>\n",
       "      <td>15.776290</td>\n",
       "      <td>12:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.621331</td>\n",
       "      <td>2.662907</td>\n",
       "      <td>0.456215</td>\n",
       "      <td>14.337914</td>\n",
       "      <td>11:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.440657</td>\n",
       "      <td>2.610077</td>\n",
       "      <td>0.463839</td>\n",
       "      <td>13.600103</td>\n",
       "      <td>11:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.342339</td>\n",
       "      <td>2.602825</td>\n",
       "      <td>0.465372</td>\n",
       "      <td>13.501832</td>\n",
       "      <td>11:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 2.98701810836792.\n",
      "Better model found at epoch 1 with valid_loss value: 2.7585082054138184.\n",
      "Better model found at epoch 2 with valid_loss value: 2.662907361984253.\n",
      "Better model found at epoch 3 with valid_loss value: 2.610077381134033.\n",
      "Better model found at epoch 4 with valid_loss value: 2.602825403213501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.303134</td>\n",
       "      <td>2.602784</td>\n",
       "      <td>0.465546</td>\n",
       "      <td>13.501275</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.306818</td>\n",
       "      <td>2.602666</td>\n",
       "      <td>0.465454</td>\n",
       "      <td>13.499682</td>\n",
       "      <td>24:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.297964</td>\n",
       "      <td>2.602541</td>\n",
       "      <td>0.465484</td>\n",
       "      <td>13.497995</td>\n",
       "      <td>1:09:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.292443</td>\n",
       "      <td>2.602486</td>\n",
       "      <td>0.465570</td>\n",
       "      <td>13.497249</td>\n",
       "      <td>11:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.300120</td>\n",
       "      <td>2.602479</td>\n",
       "      <td>0.465583</td>\n",
       "      <td>13.497156</td>\n",
       "      <td>12:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 2.6027841567993164.\n",
      "Better model found at epoch 1 with valid_loss value: 2.602666139602661.\n",
      "Better model found at epoch 2 with valid_loss value: 2.602541208267212.\n",
      "Better model found at epoch 3 with valid_loss value: 2.6024858951568604.\n",
      "Better model found at epoch 4 with valid_loss value: 2.6024789810180664.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6024789810180664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Path('full_commentaries/models/fine_tuned_language_model.pth')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.callback.fp16 import *\n",
    "from fastai.callback.schedule import fit_one_cycle\n",
    "from fastai.callback.progress import *\n",
    "\n",
    "# Define the path to the directory containing text files\n",
    "inputpath = \"./full_commentaries\"\n",
    "\n",
    "# Create a DataBlock for processing text data\n",
    "commentary_datablock = DataBlock(\n",
    "    blocks=TextBlock.from_folder(inputpath, is_lm=True),\n",
    "    get_items=get_text_files,\n",
    "    splitter=RandomSplitter(0.1)\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "commentary_dataloaders = commentary_datablock.dataloaders(inputpath, path=inputpath, bs=64, seq_len=70)\n",
    "\n",
    "# Initialize a language model learner\n",
    "learn = language_model_learner(commentary_dataloaders, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()], path=inputpath).to_fp16()\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "learn.lr_find()\n",
    "\n",
    "# Fine-tune the model using the one-cycle policy\n",
    "learn.fit_one_cycle(5, 2e-2, cbs=[SaveModelCallback()])\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, lr_max=slice(1e-7,1e-5), cbs=[SaveModelCallback()])\n",
    "\n",
    "# Evaluate the model\n",
    "validation_loss = learn.validate()[0]\n",
    "print(f\"Validation Loss: {validation_loss}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "learn.save(\"fine_tuned_language_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7189d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Snippet: nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence\n",
      "Generated Prediction: nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence Mujeeb to Buttler , SIX , this is why Buttler goes down on the knee . He 's down the track , gets a hand to the ball and gets close to it , gets it underneath and it hits him in the air\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Snippet: nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly\n",
      "Generated Prediction: nehra to mandeep four xxunk boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he did xxunk try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly , but ends up conceding a boundary Tye to Narine , FOUR , and Narine was quick to help them on this one , giving Narine a bit of room and wild swing , that allowed him to get across , Narine stands\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Snippet: henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder\n",
      "Generated Prediction: henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the xxunk which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the xxunk fielder Malinga to Chris Lynn , SIX , but he is bowling it well . Finch had him put down and Lynn followed him with a full toss . The ball came in and he threw his bat at the bowler .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Snippet: nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra hes missing the yorker by quite a bit\n",
      "Generated Prediction: nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra he s missing the yorker by quite a bit . Down the leg - side and Jadhav lets it go . The ball had to be put out , the ball came in and the ball came to him . Jadhav did n't get anywhere near the pitch but it was n't close to the\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "C:\\Users\\saite\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Snippet: nehra to kedar jadhav four four more jadhav starting to really find his timing now and hes looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure\n",
      "Generated Prediction: nehra to kedar jadhav four four more jadhav starting to really find his timing now and he s looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure . Kedar Jadhav has a good length and a length , Kedar Jadhav pulls it handsomely over mid - on . The man at deep mid - wicket is a spectator Jadeja to Rohit , SIX , gets a thick edge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snippets = [\n",
    "    \"nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence\",\n",
    "    \"nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly\",\n",
    "    \"henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder\",\n",
    "    \"nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra hes missing the yorker by quite a bit\",\n",
    "    \"nehra to kedar jadhav four four more jadhav starting to really find his timing now and hes looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure\"\n",
    "]\n",
    "\n",
    "for snippet in snippets:\n",
    "    prediction = learn.predict(snippet, 50, temperature=0.7)\n",
    "    print(f\"Original Snippet: {snippet}\")\n",
    "    print(f\"Generated Prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a24c260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Scores:\n",
      "0.6910299003322259\n",
      "0.08297567954220315\n",
      "0.3673469387755102\n",
      "0.6583184257602862\n",
      "0.780952380952381\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "original_snippets = [\n",
    "    \"nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence\",\n",
    "    \"nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly\",\n",
    "    \"henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder\",\n",
    "    \"nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra hes missing the yorker by quite a bit\",\n",
    "    \"nehra to kedar jadhav four four more jadhav starting to really find his timing now and hes looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure\"\n",
    "]\n",
    "\n",
    "generated_predictions = [\n",
    "    \"nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence Mujeeb to Buttler , SIX , this is why Buttler goes down on the knee . He 's down the track , gets a hand to the ball and gets close to it , gets it underneath and it hits him in the air\",\n",
    "    \"nehra to mandeep four xxunk boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he did xxunk try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly , but ends up conceding a boundary Tye to Narine , FOUR , and Narine was quick to help them on this one , giving Narine a bit of room and wild swing , that allowed him to get across , Narine stands\",\n",
    "    \"henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the xxunk which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the xxunk fielder Malinga to Chris Lynn , SIX , but he is bowling it well . Finch had him put down and Lynn followed him with a full toss . The ball came in and he threw his bat at the bowler .\",\n",
    "    \"nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra he s missing the yorker by quite a bit . Down the leg - side and Jadhav lets it go . The ball had to be put out , the ball came in and the ball came to him . Jadhav did n't get anywhere near the pitch but it was n't close to the\",\n",
    "    \"nehra to kedar jadhav four four more jadhav starting to really find his timing now and he s looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure . Kedar Jadhav has a good length and a length , Kedar Jadhav pulls it handsomely over mid - on . The man at deep mid - wicket is a spectator Jadeja to Rohit , SIX , gets a thick edge\"\n",
    "]\n",
    "\n",
    "def similarity_score(original, generated):\n",
    "    return difflib.SequenceMatcher(None, original, generated).ratio()\n",
    "\n",
    "similarity_scores = [similarity_score(original, generated) for original, generated in zip(original_snippets, generated_predictions)]\n",
    "\n",
    "print(\"Similarity Scores:\")\n",
    "for score in similarity_scores:\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "081c5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Scores:\n",
      "1.0\n",
      "0.9512195121951219\n",
      "0.9428571428571428\n",
      "0.96875\n",
      "0.9803921568627451\n",
      "\n",
      "Coherence Scores:\n",
      "0.023809523809523808\n",
      "0.010638297872340425\n",
      "0.03614457831325301\n",
      "0.04878048780487805\n",
      "0.028846153846153848\n",
      "\n",
      "Grammaticality Scores:\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def relevance_score(original, generated):\n",
    "    # Tokenize the original snippet and count the number of overlapping tokens with the generated prediction\n",
    "    original_tokens = set(word_tokenize(original.lower()))\n",
    "    generated_tokens = set(word_tokenize(generated.lower()))\n",
    "    overlap = len(original_tokens.intersection(generated_tokens))\n",
    "    # Calculate relevance score as the ratio of overlapping tokens to the total tokens in the original snippet\n",
    "    return overlap / len(original_tokens) if len(original_tokens) > 0 else 0\n",
    "\n",
    "def coherence_score(generated):\n",
    "    # Tokenize the generated text and calculate the average length of sentences\n",
    "    sentences = nltk.sent_tokenize(generated)\n",
    "    avg_sentence_length = sum(len(word_tokenize(sentence)) for sentence in sentences) / len(sentences)\n",
    "    # Coherence score inversely proportional to the average sentence length\n",
    "    return 1 / avg_sentence_length if avg_sentence_length > 0 else 0\n",
    "\n",
    "def grammaticality_score(generated):\n",
    "    # Tokenize the generated text and calculate the number of grammatically incorrect sentences\n",
    "    sentences = nltk.sent_tokenize(generated)\n",
    "    num_incorrect_sentences = sum(1 for sentence in sentences if len(nltk.word_tokenize(sentence)) == 0)\n",
    "    # Grammaticality score inversely proportional to the number of incorrect sentences\n",
    "    return 1 - (num_incorrect_sentences / len(sentences)) if len(sentences) > 0 else 0\n",
    "\n",
    "relevance_scores = [relevance_score(original, generated) for original, generated in zip(original_snippets, generated_predictions)]\n",
    "coherence_scores = [coherence_score(generated) for generated in generated_predictions]\n",
    "grammaticality_scores = [grammaticality_score(generated) for generated in generated_predictions]\n",
    "\n",
    "print(\"Relevance Scores:\")\n",
    "for score in relevance_scores:\n",
    "    print(score)\n",
    "\n",
    "print(\"\\nCoherence Scores:\")\n",
    "for score in coherence_scores:\n",
    "    print(score)\n",
    "\n",
    "print(\"\\nGrammaticality Scores:\")\n",
    "for score in grammaticality_scores:\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3a58e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison for snippet 1:\n",
      "Human-generated commentary: nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence\n",
      "Automatically generated commentary: nehra to mandeep four first boundary for mandeep and rcb full and on the pads needed to be put away and mandeep did just that picked it up and dispatched it over midwicket couple of bounces and into the fence Mujeeb to Buttler , SIX , this is why Buttler goes down on the knee . He 's down the track , gets a hand to the ball and gets close to it , gets it underneath and it hits him in the air\n",
      "Relevance Score: 1.0\n",
      "Coherence Score: 0.023809523809523808\n",
      "Grammaticality Score: 1.0\n",
      "\n",
      "The automatically generated commentary maintains high relevance to the human-generated commentary.\n",
      "The automatically generated commentary has moderate coherence.\n",
      "The automatically generated commentary is grammatically correct.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Comparison for snippet 2:\n",
      "Human-generated commentary: nehra to mandeep four backtoback boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he didnt try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly\n",
      "Automatically generated commentary: nehra to mandeep four xxunk boundaries to end the first over again nehra is a tad short in his length mandeep had the width to cut and he did xxunk try to hit it hard just placed it behind point and bhuvi at third man gave up the chase pretty quickly , but ends up conceding a boundary Tye to Narine , FOUR , and Narine was quick to help them on this one , giving Narine a bit of room and wild swing , that allowed him to get across , Narine stands\n",
      "Relevance Score: 0.9512195121951219\n",
      "Coherence Score: 0.010638297872340425\n",
      "Grammaticality Score: 1.0\n",
      "\n",
      "The automatically generated commentary demonstrates some relevance to the human-generated commentary.\n",
      "The automatically generated commentary has moderate coherence.\n",
      "The automatically generated commentary is grammatically correct.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Comparison for snippet 3:\n",
      "Human-generated commentary: henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the offcutter which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the midoff fielder\n",
      "Automatically generated commentary: henriques to kedar jadhav four hit straight back at henriques and he was late to get his hand up once more the xxunk which almost fooled jadhav who shimmied down and checked his drive middled it alright to beat the xxunk fielder Malinga to Chris Lynn , SIX , but he is bowling it well . Finch had him put down and Lynn followed him with a full toss . The ball came in and he threw his bat at the bowler .\n",
      "Relevance Score: 0.9428571428571428\n",
      "Coherence Score: 0.03614457831325301\n",
      "Grammaticality Score: 1.0\n",
      "\n",
      "The automatically generated commentary demonstrates some relevance to the human-generated commentary.\n",
      "The automatically generated commentary has moderate coherence.\n",
      "The automatically generated commentary is grammatically correct.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Comparison for snippet 4:\n",
      "Human-generated commentary: nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra hes missing the yorker by quite a bit\n",
      "Automatically generated commentary: nehra to kedar jadhav four another full toss its jadhav this time and he picks his spot into the deep midwicket fence not great bowling from nehra he s missing the yorker by quite a bit . Down the leg - side and Jadhav lets it go . The ball had to be put out , the ball came in and the ball came to him . Jadhav did n't get anywhere near the pitch but it was n't close to the\n",
      "Relevance Score: 0.96875\n",
      "Coherence Score: 0.04878048780487805\n",
      "Grammaticality Score: 1.0\n",
      "\n",
      "The automatically generated commentary demonstrates some relevance to the human-generated commentary.\n",
      "The automatically generated commentary has moderate coherence.\n",
      "The automatically generated commentary is grammatically correct.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n",
      "Comparison for snippet 5:\n",
      "Human-generated commentary: nehra to kedar jadhav four four more jadhav starting to really find his timing now and hes looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure\n",
      "Automatically generated commentary: nehra to kedar jadhav four four more jadhav starting to really find his timing now and he s looking dangerous this is smart batting rather than just throwing his bat at everything he knows that fine leg is up and so he waits for the back of a length delivery to come to him before pulling it over the fielder nehra under pressure . Kedar Jadhav has a good length and a length , Kedar Jadhav pulls it handsomely over mid - on . The man at deep mid - wicket is a spectator Jadeja to Rohit , SIX , gets a thick edge\n",
      "Relevance Score: 0.9803921568627451\n",
      "Coherence Score: 0.028846153846153848\n",
      "Grammaticality Score: 1.0\n",
      "\n",
      "The automatically generated commentary demonstrates some relevance to the human-generated commentary.\n",
      "The automatically generated commentary has moderate coherence.\n",
      "The automatically generated commentary is grammatically correct.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_verbal_comparison(original_snippets, generated_predictions, relevance_scores, coherence_scores, grammaticality_scores):\n",
    "    for i in range(len(original_snippets)):\n",
    "        print(f\"Comparison for snippet {i + 1}:\")\n",
    "        print(\"Human-generated commentary:\", original_snippets[i])\n",
    "        print(\"Automatically generated commentary:\", generated_predictions[i])\n",
    "        print(f\"Relevance Score: {relevance_scores[i]}\")\n",
    "        print(f\"Coherence Score: {coherence_scores[i]}\")\n",
    "        print(f\"Grammaticality Score: {grammaticality_scores[i]}\")\n",
    "        print()\n",
    "        if relevance_scores[i] == 1.0:\n",
    "            print(\"The automatically generated commentary maintains high relevance to the human-generated commentary.\")\n",
    "        elif relevance_scores[i] >= 0.5:\n",
    "            print(\"The automatically generated commentary demonstrates some relevance to the human-generated commentary.\")\n",
    "        else:\n",
    "            print(\"The automatically generated commentary lacks relevance to the human-generated commentary.\")\n",
    "        \n",
    "        if coherence_scores[i] >= 0.05:\n",
    "            print(\"The automatically generated commentary demonstrates good coherence.\")\n",
    "        elif coherence_scores[i] >= 0.01:\n",
    "            print(\"The automatically generated commentary has moderate coherence.\")\n",
    "        else:\n",
    "            print(\"The automatically generated commentary lacks coherence.\")\n",
    "        \n",
    "        if grammaticality_scores[i] == 1.0:\n",
    "            print(\"The automatically generated commentary is grammatically correct.\")\n",
    "        else:\n",
    "            print(\"The automatically generated commentary contains some grammatical errors.\")\n",
    "        print(\"-------------------------------------------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "generate_verbal_comparison(original_snippets, generated_predictions, relevance_scores, coherence_scores, grammaticality_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cc63aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in terms of percentage: 100.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(relevance_scores, coherence_scores, grammaticality_scores):\n",
    "    total_snippets = len(relevance_scores)\n",
    "    correct_count = 0\n",
    "\n",
    "    # Define thresholds for each parameter\n",
    "    relevance_threshold = 0.5  # Minimum relevance score for considering the generated commentary relevant\n",
    "    coherence_threshold = 0.01  # Minimum coherence score for considering the generated commentary coherent\n",
    "    grammaticality_threshold = 1.0  # Maximum grammaticality score for considering the generated commentary grammatical\n",
    "\n",
    "    # Iterate through each snippet\n",
    "    for relevance, coherence, grammaticality in zip(relevance_scores, coherence_scores, grammaticality_scores):\n",
    "        # Check if the generated commentary meets the thresholds for relevance, coherence, and grammaticality\n",
    "        if relevance >= relevance_threshold and coherence >= coherence_threshold and grammaticality == grammaticality_threshold:\n",
    "            correct_count += 1\n",
    "\n",
    "    # Calculate accuracy percentage\n",
    "    accuracy_percentage = (correct_count / total_snippets) * 100\n",
    "    return accuracy_percentage\n",
    "\n",
    "# Provided relevance, coherence, and grammaticality scores\n",
    "relevance_scores = [1.0, 0.9512195121951219, 0.9428571428571428, 0.96875, 0.9803921568627451]\n",
    "coherence_scores = [0.023809523809523808, 0.010638297872340425, 0.03614457831325301, 0.04878048780487805, 0.028846153846153848]\n",
    "grammaticality_scores = [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "accuracy = calculate_accuracy(relevance_scores, coherence_scores, grammaticality_scores)\n",
    "print(\"Accuracy in terms of percentage:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
